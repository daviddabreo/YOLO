{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see if it works\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.info()\n",
    "results = model('bus.jpg')\n",
    "\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "annotator = Annotator(cv2.cvtColor(results[0].orig_img, cv2.COLOR_BGR2RGB))\n",
    "boxes = results[0].boxes\n",
    "for box in boxes:\n",
    "    b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "    c = box.cls\n",
    "    annotator.box_label(b, model.names[int(c)])\n",
    "\n",
    "plt.imshow(annotator.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pipeline stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1437\n",
      "Train: 1007 files (70.1%)\n",
      "Val: 215 files (15.0%)\n",
      "Test: 215 files (15.0%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_dir = \"datasets/Annotated_FruitNet/images\"\n",
    "labels_dir = \"datasets/Annotated_FruitNet/labels\"\n",
    "\n",
    "image_train = os.path.join(images_dir, \"train\")\n",
    "image_val = os.path.join(images_dir, \"val\")\n",
    "image_test = os.path.join(images_dir, \"test\")\n",
    "\n",
    "label_train = os.path.join(labels_dir, \"train\")\n",
    "label_val = os.path.join(labels_dir, \"val\")\n",
    "label_test = os.path.join(labels_dir, \"test\")\n",
    "\n",
    "# Create test directories if they don't exist\n",
    "os.makedirs(image_test, exist_ok=True)\n",
    "os.makedirs(label_test, exist_ok=True)\n",
    "\n",
    "# Get all image files (assuming .png, modify if needed)\n",
    "image_files = []\n",
    "for folder in [image_train, image_val]:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith((\".png\", \".jpg\", \".jpeg\")):  # Add other extensions if needed\n",
    "            image_files.append(os.path.join(folder, file))\n",
    "\n",
    "# Shuffle all images (and their labels will follow)\n",
    "random.shuffle(image_files)\n",
    "total_files = len(image_files)\n",
    "\n",
    "# Calculate splits (15% test, 15% val, 70% train)\n",
    "test_count = int(0.15 * total_files)\n",
    "val_count = int(0.15 * total_files)\n",
    "train_count = total_files - test_count - val_count  # Remaining 70%\n",
    "\n",
    "# Split into groups\n",
    "test_images = image_files[:test_count]\n",
    "val_images = image_files[test_count : test_count + val_count]\n",
    "train_images = image_files[test_count + val_count :]\n",
    "\n",
    "# Function to move files while keeping images/labels in sync\n",
    "def move_sync(image_paths, dest_image_dir, dest_label_dir):\n",
    "    for img_path in image_paths:\n",
    "        # Get the base filename (e.g., \"2.png\" → \"2.txt\")\n",
    "        filename = os.path.basename(img_path)\n",
    "        label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        \n",
    "        # Determine current label location (train or val)\n",
    "        current_label_dir = label_train if \"train\" in img_path else label_val\n",
    "        label_path = os.path.join(current_label_dir, label_filename)\n",
    "        \n",
    "        # Move image\n",
    "        shutil.move(img_path, os.path.join(dest_image_dir, filename))\n",
    "        # Move corresponding label\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.move(label_path, os.path.join(dest_label_dir, label_filename))\n",
    "        else:\n",
    "            print(f\"Warning: Label {label_path} not found!\")\n",
    "\n",
    "# Move files to their new folders\n",
    "move_sync(test_images, image_test, label_test)\n",
    "move_sync(val_images, image_val, label_val)\n",
    "move_sync(train_images, image_train, label_train)\n",
    "\n",
    "print(f\"Total files: {total_files}\")\n",
    "print(f\"Train: {train_count} files ({train_count/total_files*100:.1f}%)\")\n",
    "print(f\"Val: {val_count} files ({val_count/total_files*100:.1f}%)\")\n",
    "print(f\"Test: {test_count} files ({test_count/total_files*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (pre-trained on COCO)\n",
    "model = YOLO('yolov8s.pt')  \n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/Annotated_FruitNet/data.yaml\"\n",
    "# Train the model on the custom dataset\n",
    "results = model.train(\n",
    "    data=path_to_data_yaml,  \n",
    "    epochs=50,                      # Number of epochs to train\n",
    "    batch=16,                       # Batch size\n",
    "    imgsz=256,                      # Image size\n",
    "    plots=True,                     # Generate plots\n",
    "    device=0                        # Use GPU (set -1 for CPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model = YOLO('runs/detect/train2/weights/best.pt')  # Path to your best.pt\n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/Annotated_FruitNet/data.yaml\"\n",
    "\n",
    "# Evaluate on the test set\n",
    "results = model.val(\n",
    "    data=path_to_data_yaml,\n",
    "    split='test',  # Force evaluation on the test set (not validation)\n",
    "    batch=16,\n",
    "    imgsz=256,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    device=0,       # GPU\n",
    "    save_json=True  # Optional: Save results to JSON for analysis\n",
    ")\n",
    "\n",
    "# # Print key metrics\n",
    "# print(f\"mAP50-95: {results.box.map:.4f}\")\n",
    "# print(f\"mAP50: {results.box.map50:.4f}\")\n",
    "# print(f\"Precision: {results.box.p:.4f}\")\n",
    "# print(f\"Recall: {results.box.r:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline for vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'path': \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset\",\n",
    "    'test': 'images/test/',\n",
    "    'train': 'images/train/',\n",
    "    'val': 'images/test/',\n",
    "    'nc': 6,\n",
    "    'names': ['car', 'threewheel', 'bus', 'truck', 'motorbike', 'van']\n",
    "}\n",
    "\n",
    "with open('datasets/vehicle_dataset/data.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 450 images (and labels) from val → test.\n",
      "Remaining val files: 450 images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_dir = \"datasets/vehicle_dataset/images\"\n",
    "labels_dir = \"datasets/vehicle_dataset/labels\"\n",
    "\n",
    "image_val = os.path.join(images_dir, \"val\")\n",
    "image_test = os.path.join(images_dir, \"test\")\n",
    "\n",
    "label_val = os.path.join(labels_dir, \"val\")\n",
    "label_test = os.path.join(labels_dir, \"test\")\n",
    "\n",
    "# Create test directories if they don't exist\n",
    "os.makedirs(image_test, exist_ok=True)\n",
    "os.makedirs(label_test, exist_ok=True)\n",
    "\n",
    "# Get all image files from val (assuming .png/.jpg)\n",
    "val_images = [os.path.join(image_val, f) for f in os.listdir(image_val) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "random.shuffle(val_images)  # Shuffle randomly\n",
    "\n",
    "# Calculate 50% split\n",
    "split_idx = len(val_images) // 2\n",
    "test_images = val_images[:split_idx]\n",
    "remaining_val_images = val_images[split_idx:]\n",
    "\n",
    "# Move images + labels to test/val\n",
    "for img_path in test_images:\n",
    "    # Get corresponding label (e.g., 1.jpg -> 1.txt)\n",
    "    filename = os.path.basename(img_path)\n",
    "    label_name = os.path.splitext(filename)[0] + \".txt\"\n",
    "    label_path = os.path.join(label_val, label_name)\n",
    "\n",
    "    # Move image to test\n",
    "    shutil.move(img_path, os.path.join(image_test, filename))\n",
    "    \n",
    "    # Move label to test (if exists)\n",
    "    if os.path.exists(label_path):\n",
    "        shutil.move(label_path, os.path.join(label_test, label_name))\n",
    "    else:\n",
    "        print(f\"Warning: Label {label_path} not found!\")\n",
    "\n",
    "print(f\"Moved {len(test_images)} images (and labels) from val → test.\")\n",
    "print(f\"Remaining val files: {len(remaining_val_images)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable layers: 184\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "total_layers = sum(1 for _ in model.model.named_parameters())  # Count layers\n",
    "print(f\"Total trainable layers: {total_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.102 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96  Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/cars_0_scratch/weights/best.pt, data=C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml, epochs=100, time=None, patience=100, batch=100, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=30, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'C://Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml' error  'C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\David\\anaconda3\\envs\\vit\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:574\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    573\u001b[0m }:\n\u001b[1;32m--> 574\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\David\\anaconda3\\envs\\vit\\Lib\\site-packages\\ultralytics\\data\\utils.py:312\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\David\\anaconda3\\envs\\vit\\Lib\\site-packages\\ultralytics\\utils\\checks.py:546\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 'C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m path_to_data_yaml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model on the custom dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_to_data_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Number of epochs to train\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Image size\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Freeze backbone\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Generate plots\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# resume=True,\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Use GPU (set -1 for CPU)\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\David\\anaconda3\\envs\\vit\\Lib\\site-packages\\ultralytics\\engine\\model.py:785\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    783\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\David\\anaconda3\\envs\\vit\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:137\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\David\\anaconda3\\envs\\vit\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:578\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'C://Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml' error  'C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (pre-trained on COCO)\n",
    "model = YOLO('yolov8s.pt')  \n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\"\n",
    "# Train the model on the custom dataset\n",
    "results = model.train(\n",
    "    data=path_to_data_yaml,  \n",
    "    epochs=100,                      # Number of epochs to train\n",
    "    batch=100,                       # Batch size\n",
    "    imgsz=640,                      # Image size\n",
    "    freeze=30,                      # Freeze backbone\n",
    "    plots=True,                     # Generate plots\n",
    "    # resume=True,\n",
    "    device=0                        # Use GPU (set -1 for CPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99  Python-3.12.1 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\labels\\test.cache... 450 images, 0 backgrounds, 0 corrupt: 100%|██████████| 450/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\images\\test\\car55.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:03<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        450        583      0.945        0.9      0.948      0.873\n",
      "                   car        100        111      0.951      0.874      0.937      0.896\n",
      "            threewheel         73        109      0.979      0.866      0.952       0.85\n",
      "                   bus         81         90      0.986      0.944      0.978      0.945\n",
      "                 truck         65         85      0.868      0.924      0.947      0.863\n",
      "             motorbike         88        108      0.951      0.903      0.951      0.776\n",
      "                   van         76         80      0.934      0.887      0.926      0.911\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving runs\\detect\\val\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = YOLO('runs/detect/train/weights/best.pt')  # Path to your best.pt\n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\"\n",
    "\n",
    "# Evaluate on the test set\n",
    "results = model.val(\n",
    "    data=path_to_data_yaml,\n",
    "    split='test',  # Force evaluation on the test set (not validation)\n",
    "    batch=16,\n",
    "    imgsz=256,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    device=0,       # GPU\n",
    "    save_json=True  # Optional: Save results to JSON for analysis\n",
    ")\n",
    "\n",
    "# # Print key metrics\n",
    "# print(f\"mAP50-95: {results.box.map:.4f}\")\n",
    "# print(f\"mAP50: {results.box.map50:.4f}\")\n",
    "# print(f\"Precision: {results.box.p:.4f}\")\n",
    "# print(f\"Recall: {results.box.r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99  Python-3.12.1 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\labels\\test.cache... 450 images, 0 backgrounds, 0 corrupt: 100%|██████████| 450/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\images\\test\\car55.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:07<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        450        583     0.0152     0.0725     0.0162     0.0155\n",
      "                person        100        111          0          0   0.000201   8.31e-05\n",
      "               bicycle         73        109          0          0    0.00597    0.00374\n",
      "                   car         81         90    0.00329     0.0222    0.00219    0.00193\n",
      "            motorcycle         65         85          0          0    0.00313    0.00276\n",
      "              airplane         88        108          0          0          0          0\n",
      "                   bus         76         80     0.0881      0.412     0.0859     0.0844\n",
      "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Saving runs\\detect\\val2\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = YOLO('yolov8s.pt')  # Path to your best.pt\n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\"\n",
    "\n",
    "# Evaluate on the test set\n",
    "results = model.val(\n",
    "    data=path_to_data_yaml,\n",
    "    split='test',  # Force evaluation on the test set (not validation)\n",
    "    batch=16,\n",
    "    imgsz=256,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    device=0,       # GPU\n",
    "    save_json=True  # Optional: Save results to JSON for analysis\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
