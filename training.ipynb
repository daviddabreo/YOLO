{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see if it works\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.info()\n",
    "results = model('bus.jpg')\n",
    "\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "annotator = Annotator(cv2.cvtColor(results[0].orig_img, cv2.COLOR_BGR2RGB))\n",
    "boxes = results[0].boxes\n",
    "for box in boxes:\n",
    "    b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "    c = box.cls\n",
    "    annotator.box_label(b, model.names[int(c)])\n",
    "\n",
    "plt.imshow(annotator.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pipeline stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1437\n",
      "Train: 1007 files (70.1%)\n",
      "Val: 215 files (15.0%)\n",
      "Test: 215 files (15.0%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_dir = \"datasets/Annotated_FruitNet/images\"\n",
    "labels_dir = \"datasets/Annotated_FruitNet/labels\"\n",
    "\n",
    "image_train = os.path.join(images_dir, \"train\")\n",
    "image_val = os.path.join(images_dir, \"val\")\n",
    "image_test = os.path.join(images_dir, \"test\")\n",
    "\n",
    "label_train = os.path.join(labels_dir, \"train\")\n",
    "label_val = os.path.join(labels_dir, \"val\")\n",
    "label_test = os.path.join(labels_dir, \"test\")\n",
    "\n",
    "# Create test directories if they don't exist\n",
    "os.makedirs(image_test, exist_ok=True)\n",
    "os.makedirs(label_test, exist_ok=True)\n",
    "\n",
    "# Get all image files (assuming .png, modify if needed)\n",
    "image_files = []\n",
    "for folder in [image_train, image_val]:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith((\".png\", \".jpg\", \".jpeg\")):  # Add other extensions if needed\n",
    "            image_files.append(os.path.join(folder, file))\n",
    "\n",
    "# Shuffle all images (and their labels will follow)\n",
    "random.shuffle(image_files)\n",
    "total_files = len(image_files)\n",
    "\n",
    "# Calculate splits (15% test, 15% val, 70% train)\n",
    "test_count = int(0.15 * total_files)\n",
    "val_count = int(0.15 * total_files)\n",
    "train_count = total_files - test_count - val_count  # Remaining 70%\n",
    "\n",
    "# Split into groups\n",
    "test_images = image_files[:test_count]\n",
    "val_images = image_files[test_count : test_count + val_count]\n",
    "train_images = image_files[test_count + val_count :]\n",
    "\n",
    "# Function to move files while keeping images/labels in sync\n",
    "def move_sync(image_paths, dest_image_dir, dest_label_dir):\n",
    "    for img_path in image_paths:\n",
    "        # Get the base filename (e.g., \"2.png\" → \"2.txt\")\n",
    "        filename = os.path.basename(img_path)\n",
    "        label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        \n",
    "        # Determine current label location (train or val)\n",
    "        current_label_dir = label_train if \"train\" in img_path else label_val\n",
    "        label_path = os.path.join(current_label_dir, label_filename)\n",
    "        \n",
    "        # Move image\n",
    "        shutil.move(img_path, os.path.join(dest_image_dir, filename))\n",
    "        # Move corresponding label\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.move(label_path, os.path.join(dest_label_dir, label_filename))\n",
    "        else:\n",
    "            print(f\"Warning: Label {label_path} not found!\")\n",
    "\n",
    "# Move files to their new folders\n",
    "move_sync(test_images, image_test, label_test)\n",
    "move_sync(val_images, image_val, label_val)\n",
    "move_sync(train_images, image_train, label_train)\n",
    "\n",
    "print(f\"Total files: {total_files}\")\n",
    "print(f\"Train: {train_count} files ({train_count/total_files*100:.1f}%)\")\n",
    "print(f\"Val: {val_count} files ({val_count/total_files*100:.1f}%)\")\n",
    "print(f\"Test: {test_count} files ({test_count/total_files*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (pre-trained on COCO)\n",
    "model = YOLO('yolov8s.pt')  \n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/Annotated_FruitNet/data.yaml\"\n",
    "# Train the model on the custom dataset\n",
    "results = model.train(\n",
    "    data=path_to_data_yaml,  \n",
    "    epochs=50,                      # Number of epochs to train\n",
    "    batch=16,                       # Batch size\n",
    "    imgsz=256,                      # Image size\n",
    "    plots=True,                     # Generate plots\n",
    "    device=0                        # Use GPU (set -1 for CPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model = YOLO('runs/detect/train2/weights/best.pt')  # Path to your best.pt\n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/Annotated_FruitNet/data.yaml\"\n",
    "\n",
    "# Evaluate on the test set\n",
    "results = model.val(\n",
    "    data=path_to_data_yaml,\n",
    "    split='test',  # Force evaluation on the test set (not validation)\n",
    "    batch=16,\n",
    "    imgsz=256,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    device=0,       # GPU\n",
    "    save_json=True  # Optional: Save results to JSON for analysis\n",
    ")\n",
    "\n",
    "# # Print key metrics\n",
    "# print(f\"mAP50-95: {results.box.map:.4f}\")\n",
    "# print(f\"mAP50: {results.box.map50:.4f}\")\n",
    "# print(f\"Precision: {results.box.p:.4f}\")\n",
    "# print(f\"Recall: {results.box.r:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline for vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'path': \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset\",\n",
    "    'test': 'images/test/',\n",
    "    'train': 'images/train/',\n",
    "    'val': 'images/test/',\n",
    "    'nc': 6,\n",
    "    'names': ['car', 'threewheel', 'bus', 'truck', 'motorbike', 'van']\n",
    "}\n",
    "\n",
    "with open('datasets/vehicle_dataset/data.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 450 images (and labels) from val → test.\n",
      "Remaining val files: 450 images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_dir = \"datasets/vehicle_dataset/images\"\n",
    "labels_dir = \"datasets/vehicle_dataset/labels\"\n",
    "\n",
    "image_val = os.path.join(images_dir, \"val\")\n",
    "image_test = os.path.join(images_dir, \"test\")\n",
    "\n",
    "label_val = os.path.join(labels_dir, \"val\")\n",
    "label_test = os.path.join(labels_dir, \"test\")\n",
    "\n",
    "# Create test directories if they don't exist\n",
    "os.makedirs(image_test, exist_ok=True)\n",
    "os.makedirs(label_test, exist_ok=True)\n",
    "\n",
    "# Get all image files from val (assuming .png/.jpg)\n",
    "val_images = [os.path.join(image_val, f) for f in os.listdir(image_val) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "random.shuffle(val_images)  # Shuffle randomly\n",
    "\n",
    "# Calculate 50% split\n",
    "split_idx = len(val_images) // 2\n",
    "test_images = val_images[:split_idx]\n",
    "remaining_val_images = val_images[split_idx:]\n",
    "\n",
    "# Move images + labels to test/val\n",
    "for img_path in test_images:\n",
    "    # Get corresponding label (e.g., 1.jpg -> 1.txt)\n",
    "    filename = os.path.basename(img_path)\n",
    "    label_name = os.path.splitext(filename)[0] + \".txt\"\n",
    "    label_path = os.path.join(label_val, label_name)\n",
    "\n",
    "    # Move image to test\n",
    "    shutil.move(img_path, os.path.join(image_test, filename))\n",
    "    \n",
    "    # Move label to test (if exists)\n",
    "    if os.path.exists(label_path):\n",
    "        shutil.move(label_path, os.path.join(label_test, label_name))\n",
    "    else:\n",
    "        print(f\"Warning: Label {label_path} not found!\")\n",
    "\n",
    "print(f\"Moved {len(test_images)} images (and labels) from val → test.\")\n",
    "print(f\"Remaining val files: {len(remaining_val_images)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable layers: 184\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "total_layers = sum(1 for _ in model.model.named_parameters())  # Count layers\n",
    "print(f\"Total trainable layers: {total_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (pre-trained on COCO)\n",
    "model = YOLO('yolov8s.pt')  \n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\"\n",
    "# Train the model on the custom dataset\n",
    "results = model.train(\n",
    "    data=path_to_data_yaml,  \n",
    "    epochs=100,                      # Number of epochs to train\n",
    "    batch=100,                       # Batch size\n",
    "    imgsz=640,                      # Image size\n",
    "    freeze=70,                      # Freeze backbone\n",
    "    plots=True,                     # Generate plots\n",
    "    # resume=True,\n",
    "    device=0                        # Use GPU (set -1 for CPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99  Python-3.12.1 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\labels\\test.cache... 450 images, 0 backgrounds, 0 corrupt: 100%|██████████| 450/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\images\\test\\car55.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:03<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        450        583      0.945        0.9      0.948      0.873\n",
      "                   car        100        111      0.951      0.874      0.937      0.896\n",
      "            threewheel         73        109      0.979      0.866      0.952       0.85\n",
      "                   bus         81         90      0.986      0.944      0.978      0.945\n",
      "                 truck         65         85      0.868      0.924      0.947      0.863\n",
      "             motorbike         88        108      0.951      0.903      0.951      0.776\n",
      "                   van         76         80      0.934      0.887      0.926      0.911\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving runs\\detect\\val\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = YOLO('runs/detect/train/weights/best.pt')  # Path to your best.pt\n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\"\n",
    "\n",
    "# Evaluate on the test set\n",
    "results = model.val(\n",
    "    data=path_to_data_yaml,\n",
    "    split='test',  # Force evaluation on the test set (not validation)\n",
    "    batch=16,\n",
    "    imgsz=256,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    device=0,       # GPU\n",
    "    save_json=True  # Optional: Save results to JSON for analysis\n",
    ")\n",
    "\n",
    "# # Print key metrics\n",
    "# print(f\"mAP50-95: {results.box.map:.4f}\")\n",
    "# print(f\"mAP50: {results.box.map50:.4f}\")\n",
    "# print(f\"Precision: {results.box.p:.4f}\")\n",
    "# print(f\"Recall: {results.box.r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99  Python-3.12.1 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\labels\\test.cache... 450 images, 0 backgrounds, 0 corrupt: 100%|██████████| 450/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sid\\Documents\\computer_vision\\CNN.YOLO\\datasets\\vehicle_dataset\\images\\test\\car55.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:07<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        450        583     0.0152     0.0725     0.0162     0.0155\n",
      "                person        100        111          0          0   0.000201   8.31e-05\n",
      "               bicycle         73        109          0          0    0.00597    0.00374\n",
      "                   car         81         90    0.00329     0.0222    0.00219    0.00193\n",
      "            motorcycle         65         85          0          0    0.00313    0.00276\n",
      "              airplane         88        108          0          0          0          0\n",
      "                   bus         76         80     0.0881      0.412     0.0859     0.0844\n",
      "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Saving runs\\detect\\val2\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = YOLO('yolov8s.pt')  # Path to your best.pt\n",
    "path_to_data_yaml = \"C:/Users/Sid/Documents/computer_vision/CNN.YOLO/datasets/vehicle_dataset/data.yaml\"\n",
    "\n",
    "# Evaluate on the test set\n",
    "results = model.val(\n",
    "    data=path_to_data_yaml,\n",
    "    split='test',  # Force evaluation on the test set (not validation)\n",
    "    batch=16,\n",
    "    imgsz=256,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    device=0,       # GPU\n",
    "    save_json=True  # Optional: Save results to JSON for analysis\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
